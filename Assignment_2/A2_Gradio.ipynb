{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmYsquZGyrwi"
      },
      "outputs": [],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torchtext"
      ],
      "metadata": {
        "id": "gHSxqIMIz23x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ECE1786/A2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-24prCVzbxl",
        "outputId": "3f124284-d48a-4c7a-cb4b-7d14974c1c03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ECE1786/A2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove = torchtext.vocab.GloVe(name=\"6B\",dim=100)"
      ],
      "metadata": {
        "id": "GgEiiEsFzjCY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Baseline_Model(torch.nn.Module):\n",
        "  def __init__(self, vocab):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = torch.nn.Embedding.from_pretrained(vocab.vectors)\n",
        "    self.fc = torch.nn.Linear(100, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    e = self.embedding(x)\n",
        "    out = torch.mean(e, 0).unsqueeze(0)\n",
        "    out = self.fc(out).squeeze()\n",
        "    return out\n",
        "\n",
        "class CNN_Model(torch.nn.Module):\n",
        "  def __init__(self, vocab, kernel_1, kernel_2, out_channel_1, out_channel_2, freeze):\n",
        "    super().__init__()\n",
        "    self.kernel_1 = kernel_1\n",
        "    self.kernel_2 = kernel_2\n",
        "    self.out_channel_1 = out_channel_1\n",
        "    self.out_channel_2 = out_channel_2\n",
        "    self.embedding = torch.nn.Embedding.from_pretrained(vocab.vectors, freeze=freeze)\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=out_channel_1, kernel_size=(kernel_1, 100),bias=False)\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=1, out_channels=out_channel_2, kernel_size=(kernel_2, 100),bias=False)\n",
        "    #self.pool = torch.nn.MaxPool2d(2,2)\n",
        "    self.fc = torch.nn.Linear(out_channel_1+out_channel_2,1)\n",
        "    self.do = torch.nn.Dropout(0.4)\n",
        "    self.bn1 = torch.nn.BatchNorm2d(out_channel_1)\n",
        "    self.bn2 = torch.nn.BatchNorm2d(out_channel_2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    e = self.embedding(x)\n",
        "    pool1 = torch.nn.MaxPool1d(e.shape[0]-self.kernel_1+1)\n",
        "    pool2 = torch.nn.MaxPool1d(e.shape[0]-self.kernel_2+1)\n",
        "    e = torch.transpose(e,0,1).unsqueeze(1)\n",
        "    out1 = pool1(torch.nn.functional.relu(self.conv1(e)).squeeze())\n",
        "    out2 = pool2(torch.nn.functional.relu(self.conv2(e)).squeeze())\n",
        "    out1 = self.do(out1)\n",
        "    out2 = self.do(out2)\n",
        "    out = torch.cat((out1, out2), 1).squeeze()\n",
        "    out = out.view(-1, self.out_channel_1+self.out_channel_2)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    return out.squeeze()"
      ],
      "metadata": {
        "id": "WoP8dUOV1Iwp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_base = Baseline_Model(glove)\n",
        "model_base.load_state_dict(torch.load('model_baseline.pt'))\n",
        "model_base.eval()\n",
        "model_cnn = CNN_Model(glove, 2, 4, 50, 50, False)\n",
        "model_cnn.load_state_dict(torch.load('model_cnn.pt', map_location='cpu'))\n",
        "model_cnn.eval()"
      ],
      "metadata": {
        "id": "nekSrNwx1Z0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence):\n",
        "    tokens = sentence.split()\n",
        "    token_ints = [glove.stoi.get(tok, len(glove.stoi)-1) for tok in tokens]\n",
        "\n",
        "    ### add paddings if input words are less than 5\n",
        "    while len(token_ints)<5:\n",
        "      token_ints.append(0)\n",
        "    token_tensor = torch.LongTensor(token_ints).view(-1, 1)\n",
        "    prediction_base = model_base(token_tensor)\n",
        "    prediction_cnn = model_cnn(token_tensor)\n",
        "    if prediction_base >= 0:\n",
        "      output_base = 'Subjective'\n",
        "    else:\n",
        "      output_base = 'Objective'\n",
        "    if prediction_cnn >= 0:\n",
        "      output_cnn = 'Subjective'\n",
        "    else:\n",
        "      output_cnn = 'Objective'\n",
        "    return output_base, output_cnn"
      ],
      "metadata": {
        "id": "Gyi9qBb22ZEa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Type Here...\"),\n",
        "    outputs=[\"label\", \"label\"],\n",
        "    title='Sentence Classifier',\n",
        ")\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "wQdIIuAH4_je",
        "outputId": "c8f6e1c8-505b-475f-ece9-6826fab586ac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://10472.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://10472.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f8451cf7f50>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://10472.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}